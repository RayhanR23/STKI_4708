{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhVpig18J3JM",
        "outputId": "3cd7acac-5399-4b24-87c4-7583897d688e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62hsDXKlncHa",
        "outputId": "d784c5a2-d9e2-4b00-b408-f6d47a376786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "vrI0i7mR0YoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN_dAeF-0cNY",
        "outputId": "942654e9-436d-434c-e1b6-ee6ca3030c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "XAjnaeKdzcl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESkOISUnJwIB",
        "outputId": "9820b7f4-958a-49fb-8941-969bc7d519c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-33e95228da3e>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Title': 'Query', 'Summary': query}, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        Judul Game  Similarity Score\n",
            "0                     NEO: The World Ends with You          0.254679\n",
            "1    The Elder Scrolls V: Skyrim - Special Edition          0.243522\n",
            "2                      The Elder Scrolls V: Skyrim          0.230807\n",
            "3                                   Genshin Impact          0.219339\n",
            "4                                  Hogwarts Legacy          0.200853\n",
            "..                                             ...               ...\n",
            "340                   Assassin's Creed Revelations          0.014164\n",
            "341                   Brothers: A Tale of Two Sons          0.013856\n",
            "342                               Metro 2033 Redux          0.013091\n",
            "343                                    Mass Effect          0.012427\n",
            "344              Star Wars: The Force Unleashed II          0.010252\n",
            "\n",
            "[345 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Baca data dari file CSV\n",
        "df = pd.read_csv('games.csv')\n",
        "\n",
        "# Contoh query pencarian\n",
        "query = \"open world rpg\"\n",
        "\n",
        "# Tambahkan query ke dataframe\n",
        "df = df.append({'Title': 'Query', 'Summary': query}, ignore_index=True)\n",
        "\n",
        "# Menggunakan stop words dari NLTK dan mengonversi ke list\n",
        "stop_words = list(stopwords.words('english'))\n",
        "\n",
        "# Menggunakan TF-IDF Vectorizer dengan stop words\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "X = vectorizer.fit_transform(df['Summary'].values.astype('U'))  # Pastikan nilai diubah menjadi Unicode\n",
        "\n",
        "# Menghitung cosine similarity\n",
        "cosine_similarities = cosine_similarity(X[-1], X[:-1])\n",
        "\n",
        "# Mendapatkan urutan indeks berdasarkan skor similaritas\n",
        "result_indices = cosine_similarities.argsort()[0][::-1]\n",
        "\n",
        "# Menampilkan hasil pencarian dalam bentuk tabel\n",
        "result_data = {'Judul Game': [], 'Similarity Score': []}\n",
        "\n",
        "displayed_titles = set()\n",
        "for idx in result_indices:\n",
        "    if df['Title'][idx] not in displayed_titles and cosine_similarities[0][idx] != 0:\n",
        "        result_data['Judul Game'].append(df['Title'][idx])\n",
        "        result_data['Similarity Score'].append(cosine_similarities[0][idx])\n",
        "        displayed_titles.add(df['Title'][idx])\n",
        "\n",
        "result_df = pd.DataFrame(result_data)\n",
        "print(result_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxFBiSurNjDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}